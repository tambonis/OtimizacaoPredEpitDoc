{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "#Tiago Tambonis - 2017 - 2018 - 2019 \n",
    "#Observação: Cuidado com as definições de variáveis no arquivo Geração_imuno.sh e Geração_Non_imuno.sh.\n",
    "#Na atual definição estou considerando somente 1 vizinho. Atenção ao scoring associado à GridSearch.\n",
    "#Objetivo: avaliar os resultados preditivos sem uso do Suvrel.\n",
    "#FEATURE SELECTION WITH MRMR.\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "#random_state=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função Suvrel.\n",
    "\n",
    "def suvrel(X, y, gamma=2.0, norm=None, distance=False):\n",
    "    \"\"\"\n",
    "    Return: a metric tensor for the data\n",
    "    X columns representing samples and lines dimentions\n",
    "    y labels\n",
    "    gamma is a float\n",
    "    norm:{None,\\\"unity\\\",\\\"t-test\\\"}\n",
    "    distance: {False, True} if True return a tuple (weights, D)\n",
    "    where D is the distanca matrix of the data\n",
    "    for the geometric approach method\n",
    "    \"\"\"\n",
    "\n",
    "    classes = list(set(y))\n",
    "    n_classes = len(classes)\n",
    "    dim = X.shape[1]\n",
    "\n",
    "    if norm is None or norm == \"unity\":\n",
    "        mean_cl = np.zeros((n_classes, dim))\n",
    "        for i, cl in enumerate(classes):\n",
    "            mean_cl[i] = np.mean(X[y == cl], axis=0)\n",
    "\n",
    "        smeans = np.zeros(dim)\n",
    "        for i, j in combinations(range(n_classes), 2):\n",
    "            smeans += (mean_cl[i] - mean_cl[j]) ** 2\n",
    "\n",
    "        if gamma != 2:\n",
    "            var_cl = np.zeros((n_classes, dim))\n",
    "            for cl in classes:\n",
    "                var_cl[cl] = np.var(X[y == cl], axis=0)\n",
    "            svar = np.sum(var_cl, axis=0)\n",
    "            weights = ((gamma - 2.) * svar \n",
    "                        +  gamma /( n_classes - 1) * smeans)\n",
    "        else:\n",
    "            weights = smeans\n",
    "\n",
    "        weights[weights < 0] = 0\n",
    "\n",
    "        if norm is \"unity\":\n",
    "            weights = weights / np.var(X, axis=0)\n",
    "\n",
    "        if distance:\n",
    "            return (weights / np.sqrt(np.sum(weights ** 2)),\n",
    "                    squareform(pdist(X * np.sqrt(weights))))\n",
    "        else:\n",
    "            return weights / np.sqrt(np.sum(weights ** 2))\n",
    "\n",
    "    elif norm == \"t-test\":\n",
    "        if n_classes == 2:\n",
    "            mean_cl = np.zeros((n_classes, dim))\n",
    "            var_cl = np.zeros((n_classes, dim))\n",
    "            for i, cl in enumerate(classes):\n",
    "                mean_cl[i] = np.mean(X[y == cl], axis=0)\n",
    "                var_cl[i] = np.var(X[y == cl], axis=0)\n",
    "\n",
    "            for i, j in combinations(range(n_classes), 2):\n",
    "                smeans = (mean_cl[i] - mean_cl[j]) ** 2\n",
    "                #tnorm = (var_cl[i] / np.sum([y == classes[i]])\n",
    "                         #+ var_cl[j] / np.sum([y == classes[j]]))\n",
    "\n",
    "                # case with equal variance. Edited by Marcelo 21/10/13\n",
    "                n1 = np.sum([y == classes[i]])\n",
    "                n2 = np.sum([y == classes[j]])\n",
    "                tnorm = ((n1 - 1) * var_cl[i] + (n2 - 1) * var_cl[j]) \\\n",
    "                    / (n1 + n2 - 2)\n",
    "            if gamma != 2:\n",
    "                svar = np.sum(var_cl, axis=0)\n",
    "                weights = ((gamma - 2.) * svar \n",
    "                            +  gamma /( n_classes - 1) * smeans)\n",
    "            else:\n",
    "                weights = smeans\n",
    "            weights = weights / tnorm\n",
    "            weights[weights < 0] = 0\n",
    "\n",
    "            if distance:\n",
    "                return (weights / np.sqrt(np.sum(weights ** 2)),\n",
    "                        squareform(pdist(X * np.sqrt(weights))))\n",
    "            else:\n",
    "                return weights / np.sqrt(np.sum(weights ** 2))\n",
    "\n",
    "        else:\n",
    "            print (\"error: for t-test normalization the number\" +\n",
    "                   \" of classes must be equal 2\")\n",
    "            return None\n",
    "    else:\n",
    "        print \"error: norm options are None, \\\"unity\\\" and  \\\"t-test\\\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_T(X, y, custos, gammas, kverbose, kcv, kjobs):\n",
    "\n",
    "    param_grid = {'C':custos,'gamma':gammas, 'kernel':['rbf']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=kverbose, cv=kcv, \n",
    "                        n_jobs=kjobs) #scoring='roc_auc'\n",
    "\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    return(grid.best_estimator_, grid.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(X, y, modelo):\n",
    "    \n",
    "    predic = modelo.predict(X)\n",
    "    \n",
    "    #Matriz confusão\n",
    "    print(\"Matriz confusão:\")\n",
    "    print(confusion_matrix(y, predic))\n",
    "    \n",
    "    #Medidas\n",
    "    print(\"Medidas:\")\n",
    "    print(classification_report(y ,predic))\n",
    "    \n",
    "    #Mathew\n",
    "    print(\"MCC\")\n",
    "    print(matthews_corrcoef(y, predic))\n",
    "    \n",
    "    #ROC-AUC\n",
    "    print(\"ROC-AUC\")\n",
    "    print(roc_auc_score(y, predic))\n",
    "        \n",
    "    return(accuracy_score(y, predic, normalize=True), classification_report(y, predic), \n",
    "          matthews_corrcoef(y, predic), roc_auc_score(y, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição dos parâmetros.\n",
    "\n",
    "kcv = 5\n",
    "kjobs = 7\n",
    "kverbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados \n",
    "with open('../Sequencias/DadosTreinoFeaturizados', 'rb') as fp:\n",
    "        DadosTreinoFeaturizados = pickle.load(fp)\n",
    "with open('../Sequencias/DadosTesteFeaturizados', 'rb') as fp:\n",
    "        DadosTesteFeaturizados = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DadosTreinoFeaturizados.shape)\n",
    "print(DadosTesteFeaturizados.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DadosTreinoFeaturizados.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DadosTesteFeaturizados.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino = np.array(DadosTreinoFeaturizados['Classe'])           \n",
    "y_teste = np.array(DadosTesteFeaturizados['Classe'])                         \n",
    "\n",
    "X_treino = DadosTreinoFeaturizados.drop(['Classe'], 1)\n",
    "X_teste = DadosTesteFeaturizados.drop(['Classe'], 1)\n",
    "X_treino_efetivo = np.copy(X_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalização e featurização\n",
    "\n",
    "normalizar = True\n",
    "\n",
    "if normalizar: scaler = MinMaxScaler()\n",
    "\n",
    "if normalizar: X_treino = scaler.fit_transform(X_treino)\n",
    "w = suvrel(X=X_treino, y=y_treino)\n",
    "\n",
    "X_treino_efetivo = w*X_treino_efetivo\n",
    "if normalizar: X_treino_efetivo = scaler.fit(X_treino_efetivo).transform(X_treino_efetivo)\n",
    "    \n",
    "X_teste = w*X_teste\n",
    "if normalizar: X_teste = scaler.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: #Se quiser converter para usar no libsvm.\n",
    "    \n",
    "    from sklearn.datasets import dump_svmlight_file\n",
    "    \n",
    "    dump_svmlight_file(X_treino_efetivo, y_treino, 'DadosTreinoFeatlibsvmStandarScaler.dat',zero_based=False,\n",
    "                       multilabel=False)\n",
    "    \n",
    "    dump_svmlight_file(X_teste, y_teste, 'DadosTesteFeatlibsvmStandarScaler.dat',zero_based=False,\n",
    "                       multilabel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "\n",
    "custos = np.linspace(start=128-(128*0.1*0.5),  stop =128+(128*10*0.5), num=10)\n",
    "custos = custos.tolist()\n",
    "\n",
    "gammas = np.linspace(start=0.000488281255 - (0.00048*0.1*0.5),  \n",
    "            stop = 0.000488281255 + (0.00048*0.1*0.5), num=20)\n",
    "gammas = gammas.tolist()\n",
    "\n",
    "print(\"\\n Parametros SVM: \")\n",
    "print(\"gammas: \", gammas)\n",
    "print(\"custos: \", custos)\n",
    "\n",
    "melhor_amplo, melhor_amplo_acuracias = SVM_T(X=X_treino_efetivo, y=y_treino, custos=custos, \n",
    "                     gammas=gammas, kverbose=kverbose, kcv=kcv, kjobs=kjobs)\n",
    "\n",
    "print(\"Melhores parâmetros:\")\n",
    "print(melhor_amplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n SVM amplo - Treino\")\n",
    "treino_acc, treino_report, treino_mcc, treino_AUC = info(X=X_treino_efetivo, y=y_treino, \n",
    "                                                         modelo=melhor_amplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_acuracias = melhor_amplo_acuracias\n",
    "plotcustos = []\n",
    "plotgammas = []\n",
    "plotaccs = []\n",
    "for i in range(len(modelo_acuracias)):\n",
    "    temp = modelo_acuracias[i][0]\n",
    "    plotcustos.append(temp['C'])\n",
    "    plotgammas.append(temp['gamma'])\n",
    "    plotaccs.append(modelo_acuracias[i][1])\n",
    "\n",
    "plt.scatter(plotgammas, plotcustos, edgecolors='none', c=plotaccs)\n",
    "plt.colorbar()\n",
    "plt.title('Comportamento das acuracias')\n",
    "plt.xlabel(\"Gammas\")\n",
    "plt.ylabel(\"Custos\")\n",
    "#plt.xlim(0.00055, 0.001751)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n SVM amplo - Teste\")\n",
    "#print(info(X=X_test, y=y_test, modelo=melhor_amplo))\n",
    "teste, teste_report, teste_mcc, teste_AUC = info(X=X_teste, y=y_teste, modelo=melhor_amplo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
