{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "#Naive Bayes\n",
    "#Tiago Tambonis\n",
    "#14/02/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from itertools import combinations\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função Suvrel.\n",
    "\n",
    "def suvrel(X, y, gamma=2.0, norm=None, distance=False):\n",
    "    \"\"\"\n",
    "    Return: a metric tensor for the data\n",
    "    X columns representing samples and lines dimentions\n",
    "    y labels\n",
    "    gamma is a float\n",
    "    norm:{None,\\\"unity\\\",\\\"t-test\\\"}\n",
    "    distance: {False, True} if True return a tuple (weights, D)\n",
    "    where D is the distanca matrix of the data\n",
    "    for the geometric approach method\n",
    "    \"\"\"\n",
    "\n",
    "    classes = list(set(y))\n",
    "    n_classes = len(classes)\n",
    "    dim = X.shape[1]\n",
    "\n",
    "    if norm is None or norm == \"unity\":\n",
    "        mean_cl = np.zeros((n_classes, dim))\n",
    "        for i, cl in enumerate(classes):\n",
    "            mean_cl[i] = np.mean(X[y == cl], axis=0)\n",
    "\n",
    "        smeans = np.zeros(dim)\n",
    "        for i, j in combinations(range(n_classes), 2):\n",
    "            smeans += (mean_cl[i] - mean_cl[j]) ** 2\n",
    "\n",
    "        if gamma != 2:\n",
    "            var_cl = np.zeros((n_classes, dim))\n",
    "            for cl in classes:\n",
    "                var_cl[cl] = np.var(X[y == cl], axis=0)\n",
    "            svar = np.sum(var_cl, axis=0)\n",
    "            weights = ((gamma - 2.) * svar \n",
    "                        +  gamma /( n_classes - 1) * smeans)\n",
    "        else:\n",
    "            weights = smeans\n",
    "\n",
    "        weights[weights < 0] = 0\n",
    "\n",
    "        if norm is \"unity\":\n",
    "            weights = weights / np.var(X, axis=0)\n",
    "\n",
    "        if distance:\n",
    "            return (weights / np.sqrt(np.sum(weights ** 2)),\n",
    "                    squareform(pdist(X * np.sqrt(weights))))\n",
    "        else:\n",
    "            return weights / np.sqrt(np.sum(weights ** 2))\n",
    "\n",
    "    elif norm == \"t-test\":\n",
    "        if n_classes == 2:\n",
    "            mean_cl = np.zeros((n_classes, dim))\n",
    "            var_cl = np.zeros((n_classes, dim))\n",
    "            for i, cl in enumerate(classes):\n",
    "                mean_cl[i] = np.mean(X[y == cl], axis=0)\n",
    "                var_cl[i] = np.var(X[y == cl], axis=0)\n",
    "\n",
    "            for i, j in combinations(range(n_classes), 2):\n",
    "                smeans = (mean_cl[i] - mean_cl[j]) ** 2\n",
    "                #tnorm = (var_cl[i] / np.sum([y == classes[i]])\n",
    "                         #+ var_cl[j] / np.sum([y == classes[j]]))\n",
    "\n",
    "                # case with equal variance. Edited by Marcelo 21/10/13\n",
    "                n1 = np.sum([y == classes[i]])\n",
    "                n2 = np.sum([y == classes[j]])\n",
    "                tnorm = ((n1 - 1) * var_cl[i] + (n2 - 1) * var_cl[j]) \\\n",
    "                    / (n1 + n2 - 2)\n",
    "            if gamma != 2:\n",
    "                svar = np.sum(var_cl, axis=0)\n",
    "                weights = ((gamma - 2.) * svar \n",
    "                            +  gamma /( n_classes - 1) * smeans)\n",
    "            else:\n",
    "                weights = smeans\n",
    "            weights = weights / tnorm\n",
    "            weights[weights < 0] = 0\n",
    "\n",
    "            if distance:\n",
    "                return (weights / np.sqrt(np.sum(weights ** 2)),\n",
    "                        squareform(pdist(X * np.sqrt(weights))))\n",
    "            else:\n",
    "                return weights / np.sqrt(np.sum(weights ** 2))\n",
    "\n",
    "        else:\n",
    "            print (\"error: for t-test normalization the number\" +\n",
    "                   \" of classes must be equal 2\")\n",
    "            return None\n",
    "    else:\n",
    "        print \"error: norm options are None, \\\"unity\\\" and  \\\"t-test\\\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados \n",
    "\n",
    "if False: \n",
    "\n",
    "    with open('../Sequencias/DadosTreinoFeaturizados', 'rb') as fp:\n",
    "            DadosTreinoFeaturizados = pickle.load(fp)\n",
    "    with open('../Sequencias/DadosTesteFeaturizados', 'rb') as fp:\n",
    "            DadosTesteFeaturizados = pickle.load(fp)\n",
    "\n",
    "if True: \n",
    "\n",
    "    with open('../Sequencias/DadosTreinoCru', 'rb') as fp:\n",
    "            DadosTreinoFeaturizados = pickle.load(fp)\n",
    "    with open('../Sequencias/DadosTesteCru', 'rb') as fp:\n",
    "            DadosTesteFeaturizados = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procura por meio de função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535714285714286\n",
      "0.5561224489795918\n"
     ]
    }
   ],
   "source": [
    "results = [] \n",
    "resultsnb = []\n",
    "\n",
    "for i in np.linspace(0.0005005005005005005, 0.35, 200):\n",
    "\n",
    "    y_treino = np.array(DadosTreinoFeaturizados['Classe'])           \n",
    "    y_teste = np.array(DadosTesteFeaturizados['Classe'])                         \n",
    "\n",
    "    X_treino = np.array(DadosTreinoFeaturizados.drop(['Classe'], 1))\n",
    "    X_teste = np.array(DadosTesteFeaturizados.drop(['Classe'], 1))\n",
    "    X_treino_efetivo = np.copy(X_treino)\n",
    "\n",
    "    #Normalização e featurização\n",
    "\n",
    "    normalizar = False\n",
    "    usarsuvrel = True\n",
    "\n",
    "    if normalizar:\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_treino = scaler.fit(X_treino).transform(X_treino)\n",
    "\n",
    "    if usarsuvrel: \n",
    "\n",
    "        w = suvrel(X=X_treino, y=y_treino)\n",
    "        #w = np.sqrt(w)\n",
    "\n",
    "        X_treino_efetivo = w*X_treino_efetivo\n",
    "        X_teste = w*X_teste\n",
    "        \n",
    "        #X_treino_efetivo = scaler.fit(X_treino_efetivo).transform(X_treino_efetivo)\n",
    "        #X_teste = scaler.transform(X_teste)\n",
    "\n",
    "    X_treino_efetivo = X_treino_efetivo[:, w>i]\n",
    "    X_teste = X_teste[:, w>i]\n",
    "\n",
    "    bnb = BernoulliNB(binarize=0)\n",
    "    bnb.fit(X_treino_efetivo, y_treino)\n",
    "    #print(bnb.score(X_teste, y_teste))\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_treino_efetivo, y_treino)\n",
    "    #print(gnb.score(X_teste, y_teste))\n",
    "    \n",
    "    results.append(gnb.score(X_teste, y_teste))\n",
    "    resultsnb.append(bnb.score(X_teste, y_teste))\n",
    "\n",
    "results = np.array(results)\n",
    "resultsnb = np.array(resultsnb)\n",
    "\n",
    "print(np.max(results))\n",
    "print(np.max(resultsnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n",
      "0.5548469387755102\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli\n",
    "\n",
    "for j in np.linspace(0, 1, 10):\n",
    "    \n",
    "    resultsnb = []\n",
    "    \n",
    "    for i in np.linspace(0.0005005005005005005, 0.35, 100):\n",
    "\n",
    "        y_treino = np.array(DadosTreinoFeaturizados['Classe'])           \n",
    "        y_teste = np.array(DadosTesteFeaturizados['Classe'])                         \n",
    "\n",
    "        X_treino = np.array(DadosTreinoFeaturizados.drop(['Classe'], 1))\n",
    "        X_teste = np.array(DadosTesteFeaturizados.drop(['Classe'], 1))\n",
    "        X_treino_efetivo = np.copy(X_treino)\n",
    "\n",
    "        #Normalização e featurização\n",
    "\n",
    "        normalizar = True\n",
    "        usarsuvrel = True\n",
    "\n",
    "        if normalizar:\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                X_treino = scaler.fit(X_treino).transform(X_treino)\n",
    "\n",
    "        if usarsuvrel: \n",
    "\n",
    "            w = suvrel(X=X_treino, y=y_treino)\n",
    "            #w = np.sqrt(w)\n",
    "\n",
    "            X_treino_efetivo = w*X_treino_efetivo\n",
    "            X_teste = w*X_teste\n",
    "\n",
    "            X_treino_efetivo = scaler.fit(X_treino_efetivo).transform(X_treino_efetivo)\n",
    "            X_teste = scaler.transform(X_teste)\n",
    "\n",
    "        X_treino_efetivo = X_treino_efetivo[:, w>i]\n",
    "        X_teste = X_teste[:, w>i]\n",
    "\n",
    "        bnb = BernoulliNB(binarize=j)\n",
    "        bnb.fit(X_treino_efetivo, y_treino)\n",
    "        #print(bnb.score(X_teste, y_teste))\n",
    "\n",
    "        #gnb = GaussianNB()\n",
    "        #gnb.fit(X_treino_efetivo, y_treino)\n",
    "        #print(gnb.score(X_teste, y_teste))\n",
    "\n",
    "        #results.append(gnb.score(X_teste, y_teste))\n",
    "        resultsnb.append(bnb.score(X_teste, y_teste))\n",
    "\n",
    "    #results = np.array(results)\n",
    "    resultsnb = np.array(resultsnb)\n",
    "\n",
    "    #print(np.max(results))\n",
    "    print(np.max(resultsnb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
